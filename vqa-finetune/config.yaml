data:
  format: json
  path: /home/abdelrahman.elsayed/GP/vqa-finetune/data_preprocessed.csv

model:
  name: blip
  type: large
  ft : lora
  alpha: 1
  val_freq: 2
  num_epochs: 50
  patience: 10
  batch_size: 24
  learning_rate: 1e-5
  lora:
    rank: 8
    alpha: 32
    dropout: 0.1
  target_modules:
    - qkv
